{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anthropic\n",
      "  Using cached anthropic-0.25.6-py3-none-any.whl (870 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python311\\lib\\site-packages (from anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python311\\lib\\site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python311\\lib\\site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\python311\\lib\\site-packages (from anthropic) (2.6.4)\n",
      "Requirement already satisfied: sniffio in c:\\python311\\lib\\site-packages (from anthropic) (1.3.0)\n",
      "Collecting tokenizers>=0.13.0 (from anthropic)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python311\\lib\\site-packages (from anthropic) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.0->anthropic)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vince\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Collecting requests (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vince\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.4)\n",
      "Installing collected packages: requests, huggingface-hub, tokenizers, anthropic\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python311\\\\Scripts\\\\huggingface-cli.exe' -> 'c:\\\\Python311\\\\Scripts\\\\huggingface-cli.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3642496310.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    max_tokens = 1024\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_questions(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        questions = file.readlines()\n",
    "    return [q.strip() for q in questions]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "api_key_ant = api_key\n",
    "\n",
    "client = Client.anthropic(api_key = api_key_ant)\n",
    "\n",
    "client.messages.create(\n",
    "    model = #haiku?,\n",
    "    max_tokens = 1024\n",
    "    messages=[{\"role\": \"user\", \"content\": question}]\n",
    ")\n",
    "print (messages.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def political_api_response(text, api_key):\n",
    "    url = \"https://api.thebipartisanpress.com/api/endpoints/beta/robert/\"\n",
    "    setup = {\"API\": api_key, \"Text\": text}\n",
    "    response = requests.post(url, data=setup)\n",
    "    print(response.text)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_response_to_csv(question, response, score, csv_file):\n",
    "    # Open the file in append mode ('a') to add each row without overwriting\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([question, response, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_dotenv()\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "    bias_api_key = os.getenv('BIAS_API_KEY')\n",
    "\n",
    "    questions = read_questions('questions.txt')\n",
    "    csv_file = 'gpt-4-0125-preview_responses.csv'\n",
    "    \n",
    "    # Initialize the CSV file with headers before processing questions\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Question', 'Response', 'Score'])\n",
    "    \n",
    "    for question in questions:\n",
    "        response = get_gpt4_response(question)\n",
    "        score = political_api_response(response, bias_api_key)\n",
    "        write_response_to_csv(question, response, score, csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
